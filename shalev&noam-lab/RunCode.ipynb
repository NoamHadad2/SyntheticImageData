{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!find \"/content/drive/MyDrive/training_kitti_raw\" -maxdepth 6 -type d -name \"image_2\"\n",
        "!find \"/content/drive/MyDrive/training_kitti_raw\" -maxdepth 6 -type d -name \"label_2\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fETgUs2Ci6R",
        "outputId": "5c40907a-842c-47d2-811c-8ec74046c52e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/training_kitti_raw/object_image/testing/image_2\n",
            "/content/drive/MyDrive/training_kitti_raw/object_image/training/image_2\n",
            "/content/drive/MyDrive/training_kitti_raw/object_label/training/label_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/training/prepare_kitti_yolo_fast.py\n",
        "import argparse, random, shutil, os, time\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "MAP = {\n",
        "    \"Car\": 0,\n",
        "    \"Van\": 0,\n",
        "    \"Truck\": 0,            # ×× ×œ× ×¨×•×¦×” Truck ×›-Car, ×ª××—×§ ××ª ×”×©×•×¨×” ×”×–×•\n",
        "    \"Pedestrian\": 1,\n",
        "    \"Person_sitting\": 1,\n",
        "    \"Cyclist\": 2,\n",
        "}\n",
        "IMG_EXTS = {\".png\", \".jpg\", \".jpeg\"}\n",
        "\n",
        "def yolo_line(cls, left, top, right, bottom, w, h):\n",
        "    x = ((left + right) / 2.0) / w\n",
        "    y = ((top + bottom) / 2.0) / h\n",
        "    bw = (right - left) / w\n",
        "    bh = (bottom - top) / h\n",
        "    # clamp\n",
        "    x = max(0.0, min(1.0, x)); y = max(0.0, min(1.0, y))\n",
        "    bw = max(0.0, min(1.0, bw)); bh = max(0.0, min(1.0, bh))\n",
        "    return f\"{cls} {x:.6f} {y:.6f} {bw:.6f} {bh:.6f}\\n\"\n",
        "\n",
        "def link_or_copy(src: Path, dst: Path, mode: str):\n",
        "    if dst.exists():\n",
        "        return\n",
        "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if mode == \"symlink\":\n",
        "        try:\n",
        "            os.symlink(str(src), str(dst))\n",
        "            return\n",
        "        except Exception:\n",
        "            # fallback to copy if symlink fails\n",
        "            pass\n",
        "    shutil.copy2(src, dst)\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--img_dir\", required=True)    # .../training/image_2\n",
        "    ap.add_argument(\"--lbl_dir\", required=True)    # .../training/label_2\n",
        "    ap.add_argument(\"--work_dir\", default=\"/content/yolo_dataset_kitti\")  # fast local\n",
        "    ap.add_argument(\"--seed\", type=int, default=123)\n",
        "    ap.add_argument(\"--train\", type=float, default=0.7)\n",
        "    ap.add_argument(\"--val\", type=float, default=0.15)\n",
        "    ap.add_argument(\"--test\", type=float, default=0.15)\n",
        "    ap.add_argument(\"--mode\", choices=[\"symlink\",\"copy\"], default=\"symlink\")\n",
        "    ap.add_argument(\"--limit\", type=int, default=0, help=\"debug: use only first N images\")\n",
        "    ap.add_argument(\"--export_dir\", default=\"\", help=\"optional: copy final dataset to Drive (slow)\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    img_dir = Path(args.img_dir)\n",
        "    lbl_dir = Path(args.lbl_dir)\n",
        "    assert img_dir.exists(), f\"missing img_dir: {img_dir}\"\n",
        "    assert lbl_dir.exists(), f\"missing lbl_dir: {lbl_dir}\"\n",
        "\n",
        "    out = Path(args.work_dir)\n",
        "    # reset output\n",
        "    if out.exists():\n",
        "        shutil.rmtree(out)\n",
        "    for s in [\"train\",\"val\",\"test\"]:\n",
        "        (out/\"images\"/s).mkdir(parents=True, exist_ok=True)\n",
        "        (out/\"labels\"/s).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    imgs = sorted([p for p in img_dir.iterdir() if p.suffix.lower() in IMG_EXTS])\n",
        "    if not imgs:\n",
        "        raise RuntimeError(f\"No images found in {img_dir}\")\n",
        "\n",
        "    if args.limit and args.limit > 0:\n",
        "        imgs = imgs[:args.limit]\n",
        "\n",
        "    rnd = random.Random(args.seed)\n",
        "    rnd.shuffle(imgs)\n",
        "\n",
        "    n = len(imgs)\n",
        "    n_train = int(n*args.train)\n",
        "    n_val = int(n*args.val)\n",
        "    splits = {\n",
        "        \"train\": imgs[:n_train],\n",
        "        \"val\": imgs[n_train:n_train+n_val],\n",
        "        \"test\": imgs[n_train+n_val:],\n",
        "    }\n",
        "\n",
        "    print(\"Total images:\", n, \"splits:\", {k: len(v) for k,v in splits.items()})\n",
        "    t0 = time.time()\n",
        "\n",
        "    for split, arr in splits.items():\n",
        "        for i, img_path in enumerate(arr, start=1):\n",
        "            # link/copy image\n",
        "            dst_img = out/\"images\"/split/img_path.name\n",
        "            link_or_copy(img_path, dst_img, args.mode)\n",
        "\n",
        "            # read image size (lightweight)\n",
        "            with Image.open(img_path) as im:\n",
        "                w, h = im.size\n",
        "\n",
        "            # convert label\n",
        "            kitti_label = lbl_dir/(img_path.stem + \".txt\")\n",
        "            out_lines = []\n",
        "            if kitti_label.exists():\n",
        "                for line in kitti_label.read_text().splitlines():\n",
        "                    if not line.strip():\n",
        "                        continue\n",
        "                    parts = line.split()\n",
        "                    t = parts[0]\n",
        "                    if t == \"DontCare\" or t not in MAP:\n",
        "                        continue\n",
        "                    left, top, right, bottom = map(float, parts[4:8])\n",
        "                    if right <= left or bottom <= top:\n",
        "                        continue\n",
        "                    out_lines.append(yolo_line(MAP[t], left, top, right, bottom, w, h))\n",
        "\n",
        "            (out/\"labels\"/split/(img_path.stem + \".txt\")).write_text(\"\".join(out_lines))\n",
        "\n",
        "            if i % 200 == 0 or i == len(arr):\n",
        "                dt = time.time() - t0\n",
        "                print(f\"[{split}] {i}/{len(arr)} done | elapsed {dt:.1f}s\")\n",
        "\n",
        "    # write data.yaml\n",
        "    (out/\"data.yaml\").write_text(\n",
        "        f\"\"\"path: {out}\n",
        "train: images/train\n",
        "val: images/val\n",
        "test: images/test\n",
        "names:\n",
        "  0: Car\n",
        "  1: Pedestrian\n",
        "  2: Cyclist\n",
        "\"\"\"\n",
        "    )\n",
        "    print(\"DONE:\", out)\n",
        "    print(\"data.yaml:\", out/\"data.yaml\")\n",
        "\n",
        "    # optional export to Drive (slow!)\n",
        "    if args.export_dir.strip():\n",
        "        exp = Path(args.export_dir)\n",
        "        if exp.exists():\n",
        "            shutil.rmtree(exp)\n",
        "        shutil.copytree(out, exp, symlinks=False)  # export as real files\n",
        "        print(\"EXPORTED to:\", exp)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIaZ4jOQCn9d",
        "outputId": "2fcdfcf2-02ba-44d2-d5e6-4078973285fc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/drive/MyDrive/training/prepare_kitti_yolo_fast.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "img_dir = Path(\"/content/drive/MyDrive/training_kitti_raw/object_image/training/image_2\")\n",
        "lbl_dir = Path(\"/content/drive/MyDrive/training_kitti_raw/object_label/training/label_2\")\n",
        "\n",
        "imgs = sorted(img_dir.glob(\"*.png\"))\n",
        "print(\"num images:\", len(imgs))\n",
        "print(\"first image:\", imgs[0])\n",
        "\n",
        "# ×‘×“×™×§×ª ×¤×ª×™×—×ª ×ª××•× ×”\n",
        "im = Image.open(imgs[0])\n",
        "print(\"size:\", im.size)\n",
        "\n",
        "# ×‘×“×™×§×ª ×œ×™×™×‘×œ\n",
        "lab = lbl_dir / (imgs[0].stem + \".txt\")\n",
        "print(\"label exists:\", lab.exists())\n",
        "print(\"label sample:\\n\", lab.read_text().splitlines()[:3] if lab.exists() else \"NO LABEL\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-sN07v2Fogt",
        "outputId": "6fa2d521-aa67-407c-d197-3ed69447c983"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num images: 7481\n",
            "first image: /content/drive/MyDrive/training_kitti_raw/object_image/training/image_2/000000.png\n",
            "size: (1224, 370)\n",
            "label exists: True\n",
            "label sample:\n",
            " ['Pedestrian 0.00 0 -0.20 712.40 143.00 810.73 307.92 1.89 0.48 1.20 1.84 1.47 8.41 0.01']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, shutil\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "MAP = {\"Car\":0,\"Van\":0,\"Truck\":0,\"Pedestrian\":1,\"Person_sitting\":1,\"Cyclist\":2}\n",
        "\n",
        "img_dir = Path(\"/content/drive/MyDrive/training_kitti_raw/object_image/training/image_2\")\n",
        "lbl_dir = Path(\"/content/drive/MyDrive/training_kitti_raw/object_label/training/label_2\")\n",
        "\n",
        "out = Path(\"/content/yolo_kitti_small\")\n",
        "if out.exists():\n",
        "    shutil.rmtree(out)\n",
        "(out/\"images/train\").mkdir(parents=True, exist_ok=True)\n",
        "(out/\"labels/train\").mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "imgs = sorted(img_dir.glob(\"*.png\"))\n",
        "sample = random.sample(imgs, 20)\n",
        "\n",
        "def yolo_line(cls, left, top, right, bottom, w, h):\n",
        "    x = ((left + right)/2)/w\n",
        "    y = ((top + bottom)/2)/h\n",
        "    bw = (right-left)/w\n",
        "    bh = (bottom-top)/h\n",
        "    return f\"{cls} {x:.6f} {y:.6f} {bw:.6f} {bh:.6f}\\n\"\n",
        "\n",
        "for i, img_path in enumerate(sample, 1):\n",
        "    # copy image (×œ××§×•××™ -> ××”×™×¨ ×™×•×ª×¨ ×××©×¨ ×œ-Drive)\n",
        "    shutil.copy2(img_path, out/\"images/train\"/img_path.name)\n",
        "\n",
        "    # get size\n",
        "    with Image.open(img_path) as im:\n",
        "        w,h = im.size\n",
        "\n",
        "    # convert label\n",
        "    kitti = lbl_dir/(img_path.stem+\".txt\")\n",
        "    lines=[]\n",
        "    if kitti.exists():\n",
        "        for line in kitti.read_text().splitlines():\n",
        "            if not line.strip():\n",
        "                continue\n",
        "            p=line.split()\n",
        "            t=p[0]\n",
        "            if t==\"DontCare\" or t not in MAP:\n",
        "                continue\n",
        "            left,top,right,bottom = map(float, p[4:8])\n",
        "            if right<=left or bottom<=top:\n",
        "                continue\n",
        "            lines.append(yolo_line(MAP[t], left, top, right, bottom, w, h))\n",
        "\n",
        "    (out/\"labels/train\"/(img_path.stem+\".txt\")).write_text(\"\".join(lines))\n",
        "\n",
        "    print(f\"{i}/20 done: {img_path.name}\")\n",
        "\n",
        "(out/\"data.yaml\").write_text(f\"\"\"path: {out}\n",
        "train: images/train\n",
        "val: images/train\n",
        "names:\n",
        "  0: Car\n",
        "  1: Pedestrian\n",
        "  2: Cyclist\n",
        "\"\"\")\n",
        "\n",
        "print(\"DONE:\", out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHTbwyCAH57w",
        "outputId": "42db2c7c-ea5d-4498-c81e-10150210d80b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/20 done: 006983.png\n",
            "2/20 done: 004771.png\n",
            "3/20 done: 003390.png\n",
            "4/20 done: 006889.png\n",
            "5/20 done: 005572.png\n",
            "6/20 done: 003196.png\n",
            "7/20 done: 000002.png\n",
            "8/20 done: 001533.png\n",
            "9/20 done: 004983.png\n",
            "10/20 done: 004092.png\n",
            "11/20 done: 003871.png\n",
            "12/20 done: 007311.png\n",
            "13/20 done: 004815.png\n",
            "14/20 done: 001826.png\n",
            "15/20 done: 002811.png\n",
            "16/20 done: 004526.png\n",
            "17/20 done: 005936.png\n",
            "18/20 done: 001064.png\n",
            "19/20 done: 005978.png\n",
            "20/20 done: 004411.png\n",
            "DONE: /content/yolo_kitti_small\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah /content/yolo_kitti_small/images/train | head\n",
        "!ls -lah /content/yolo_kitti_small/labels/train | head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9o5NncNH9tv",
        "outputId": "df0fcae5-4ae7-47d9-d2cb-6e0de1426b5d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 16M\n",
            "drwxr-xr-x 2 root root 4.0K Dec 18 01:43 .\n",
            "drwxr-xr-x 3 root root 4.0K Dec 18 01:42 ..\n",
            "-rw------- 1 root root 750K Dec 18 00:23 000002.png\n",
            "-rw------- 1 root root 835K Dec 18 00:23 001064.png\n",
            "-rw------- 1 root root 593K Dec 18 00:23 001533.png\n",
            "-rw------- 1 root root 834K Dec 18 00:23 001826.png\n",
            "-rw------- 1 root root 874K Dec 18 00:23 002811.png\n",
            "-rw------- 1 root root 786K Dec 18 00:23 003196.png\n",
            "-rw------- 1 root root 803K Dec 18 00:23 003390.png\n",
            "total 88K\n",
            "drwxr-xr-x 2 root root 4.0K Dec 18 01:43 .\n",
            "drwxr-xr-x 3 root root 4.0K Dec 18 01:42 ..\n",
            "-rw-r--r-- 1 root root   38 Dec 18 01:43 000002.txt\n",
            "-rw-r--r-- 1 root root   76 Dec 18 01:43 001064.txt\n",
            "-rw-r--r-- 1 root root  380 Dec 18 01:43 001533.txt\n",
            "-rw-r--r-- 1 root root  114 Dec 18 01:43 001826.txt\n",
            "-rw-r--r-- 1 root root   38 Dec 18 01:43 002811.txt\n",
            "-rw-r--r-- 1 root root   76 Dec 18 01:43 003196.txt\n",
            "-rw-r--r-- 1 root root  342 Dec 18 01:42 003390.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random, shutil, yaml\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "\n",
        "# ××§×•×¨×•×ª KITTI ×”×¨×©××™ ××¦×œ×š\n",
        "IMG_DIR = Path(\"/content/drive/MyDrive/training_kitti_raw/object_image/training/image_2\")\n",
        "LBL_DIR = Path(\"/content/drive/MyDrive/training_kitti_raw/object_label/training/label_2\")\n",
        "\n",
        "# ×™×¢×“ (×“××˜×”×¡×˜ ×§×˜×Ÿ)\n",
        "OUT = Path(\"/content/drive/MyDrive/training/yolo_kitti_100\")\n",
        "if OUT.exists():\n",
        "    shutil.rmtree(OUT)\n",
        "\n",
        "for s in [\"train\",\"val\",\"test\"]:\n",
        "    (OUT/\"images\"/s).mkdir(parents=True, exist_ok=True)\n",
        "    (OUT/\"labels\"/s).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "MAP = {\"Car\":0, \"Van\":0, \"Truck\":0, \"Pedestrian\":1, \"Person_sitting\":1, \"Cyclist\":2}\n",
        "\n",
        "def yolo_line(cls, left, top, right, bottom, w, h):\n",
        "    x = ((left + right)/2)/w\n",
        "    y = ((top + bottom)/2)/h\n",
        "    bw = (right-left)/w\n",
        "    bh = (bottom-top)/h\n",
        "    x = max(0.0, min(1.0, x)); y = max(0.0, min(1.0, y))\n",
        "    bw = max(0.0, min(1.0, bw)); bh = max(0.0, min(1.0, bh))\n",
        "    return f\"{cls} {x:.6f} {y:.6f} {bw:.6f} {bh:.6f}\\n\"\n",
        "\n",
        "imgs = sorted(IMG_DIR.glob(\"*.png\"))\n",
        "print(\"Total KITTI training images:\", len(imgs))\n",
        "\n",
        "random.seed(123)\n",
        "sample = random.sample(imgs, 100)\n",
        "\n",
        "# split 70/15/15\n",
        "train = sample[:70]\n",
        "val   = sample[70:85]\n",
        "test  = sample[85:]\n",
        "\n",
        "splits = {\"train\": train, \"val\": val, \"test\": test}\n",
        "\n",
        "for split, arr in splits.items():\n",
        "    for i, img_path in enumerate(arr, 1):\n",
        "        shutil.copy2(img_path, OUT/\"images\"/split/img_path.name)\n",
        "\n",
        "        with Image.open(img_path) as im:\n",
        "            w, h = im.size\n",
        "\n",
        "        kitti = LBL_DIR / (img_path.stem + \".txt\")\n",
        "        out_lines = []\n",
        "        if kitti.exists():\n",
        "            for line in kitti.read_text().splitlines():\n",
        "                if not line.strip():\n",
        "                    continue\n",
        "                p = line.split()\n",
        "                t = p[0]\n",
        "                if t == \"DontCare\" or t not in MAP:\n",
        "                    continue\n",
        "                left, top, right, bottom = map(float, p[4:8])\n",
        "                if right <= left or bottom <= top:\n",
        "                    continue\n",
        "                out_lines.append(yolo_line(MAP[t], left, top, right, bottom, w, h))\n",
        "\n",
        "        (OUT/\"labels\"/split/(img_path.stem+\".txt\")).write_text(\"\".join(out_lines))\n",
        "\n",
        "    print(split, \"done:\", len(arr))\n",
        "\n",
        "# data.yaml\n",
        "data = {\n",
        "    \"path\": str(OUT),\n",
        "    \"train\": \"images/train\",\n",
        "    \"val\": \"images/val\",\n",
        "    \"test\": \"images/test\",\n",
        "    \"names\": {0:\"Car\", 1:\"Pedestrian\", 2:\"Cyclist\"}\n",
        "}\n",
        "(OUT/\"data.yaml\").write_text(yaml.safe_dump(data, sort_keys=False))\n",
        "print(\"Wrote:\", OUT/\"data.yaml\")\n",
        "print(\"DONE:\", OUT)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGSU6FRaICfv",
        "outputId": "470d4a12-80b1-4309-eb58-09665d81f6f7"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total KITTI training images: 7481\n",
            "train done: 70\n",
            "val done: 15\n",
            "test done: 15\n",
            "Wrote: /content/drive/MyDrive/training/yolo_kitti_100/data.yaml\n",
            "DONE: /content/drive/MyDrive/training/yolo_kitti_100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lah \"/content/drive/MyDrive/training/yolo_kitti_100/images/train\" | head\n",
        "!ls -lah \"/content/drive/MyDrive/training/yolo_kitti_100/labels/train\" | head\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkZ2mVaKIUZS",
        "outputId": "5b9f27de-3b8e-4e6e-9946-b5b5a5f22922"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 56M\n",
            "-rw------- 1 root root 970K Dec 18 00:23 000013.png\n",
            "-rw------- 1 root root 870K Dec 18 00:23 000054.png\n",
            "-rw------- 1 root root 879K Dec 18 00:23 000173.png\n",
            "-rw------- 1 root root 726K Dec 18 00:23 000301.png\n",
            "-rw------- 1 root root 809K Dec 18 00:23 000312.png\n",
            "-rw------- 1 root root 833K Dec 18 00:23 000359.png\n",
            "-rw------- 1 root root 904K Dec 18 00:23 000425.png\n",
            "-rw------- 1 root root 722K Dec 18 00:23 000428.png\n",
            "-rw------- 1 root root 650K Dec 18 00:23 000572.png\n",
            "total 37K\n",
            "-rw------- 1 root root  38 Dec 18 01:44 000013.txt\n",
            "-rw------- 1 root root  38 Dec 18 01:44 000054.txt\n",
            "-rw------- 1 root root 266 Dec 18 01:45 000173.txt\n",
            "-rw------- 1 root root 266 Dec 18 01:45 000301.txt\n",
            "-rw------- 1 root root 190 Dec 18 01:44 000312.txt\n",
            "-rw------- 1 root root 114 Dec 18 01:45 000359.txt\n",
            "-rw------- 1 root root 266 Dec 18 01:44 000425.txt\n",
            "-rw------- 1 root root 152 Dec 18 01:44 000428.txt\n",
            "-rw------- 1 root root 342 Dec 18 01:44 000572.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics\n",
        "!yolo detect train model=yolov8n.pt data=\"/content/drive/MyDrive/training/yolo_kitti_100/data.yaml\" \\\n",
        "  epochs=30 imgsz=640 project=\"/content/runs_100\" name=\"baseline\" exist_ok=True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evGdoF6qIX9k",
        "outputId": "afb8077c-fc28-4181-a78a-21493cbf4cac"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/training/yolo_kitti_100/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=baseline, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs_100, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs_100/baseline, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 300.7Â±38.8 MB/s, size: 826.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100/labels/train... 70 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 70/70 209.9it/s 0.3s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/training/yolo_kitti_100/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.1 ms, read: 133.7Â±86.4 MB/s, size: 792.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100/labels/val... 15 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 134.4it/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/training/yolo_kitti_100/labels/val.cache\n",
            "Plotting labels to /content/runs_100/baseline/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs_100/baseline\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30       2.2G       1.65      3.809      1.183         97        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.1s/it 5.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
            "                   all         15         85    0.00964      0.472     0.0363     0.0236\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      2.22G      1.608      3.268      1.195         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.0it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.9it/s 0.1s\n",
            "                   all         15         85     0.0145      0.573     0.0732     0.0412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      2.24G      1.658       2.41      1.142         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.7it/s 0.1s\n",
            "                   all         15         85     0.0126      0.573       0.11     0.0656\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      2.26G       1.45      1.713      1.079         53        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.6it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.0it/s 0.1s\n",
            "                   all         15         85     0.0123      0.573      0.116     0.0669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      2.28G      1.459      1.588      1.106         88        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.8it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.4it/s 0.1s\n",
            "                   all         15         85     0.0114      0.549      0.127     0.0616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      2.29G      1.445       1.59      1.095         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.5it/s 0.1s\n",
            "                   all         15         85     0.0109      0.533      0.115      0.046\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      2.31G      1.422      1.486      1.104         81        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.6it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.4it/s 0.1s\n",
            "                   all         15         85     0.0124      0.553      0.126     0.0509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      2.33G      1.311      1.418      1.106         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.8it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.0it/s 0.1s\n",
            "                   all         15         85     0.0126      0.553      0.136     0.0645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      2.35G      1.361      1.346      1.128         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.1it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.9it/s 0.1s\n",
            "                   all         15         85     0.0141      0.577      0.439      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      2.36G        1.3       1.36      1.077         50        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.6it/s 0.1s\n",
            "                   all         15         85     0.0137      0.573      0.483      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      2.38G      1.306      1.464       1.05         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.1it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.8it/s 0.1s\n",
            "                   all         15         85     0.0147      0.585      0.501      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30       2.4G       1.25      1.311       1.04         61        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.0it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.0it/s 0.1s\n",
            "                   all         15         85     0.0157      0.931      0.514       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      2.42G      1.309      1.291      1.042         74        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.0it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.1it/s 0.1s\n",
            "                   all         15         85     0.0155      0.931      0.561      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      2.43G      1.315      1.272      1.055         59        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.1it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.9it/s 0.1s\n",
            "                   all         15         85      0.987     0.0988      0.387      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      2.45G      1.227      1.221      1.051         68        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.3it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.0it/s 0.1s\n",
            "                   all         15         85      0.986     0.0948      0.307       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      2.47G      1.199      1.206      1.043         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.0it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.6it/s 0.1s\n",
            "                   all         15         85      0.975     0.0976      0.301      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      2.48G      1.164      1.125      1.031         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.9it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.0it/s 0.1s\n",
            "                   all         15         85       0.98      0.125      0.311      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30       2.5G      1.203      1.108       1.03         79        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.5it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.7it/s 0.1s\n",
            "                   all         15         85      0.991       0.14      0.313      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      2.52G      1.216      1.131      1.013         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.5it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.7it/s 0.1s\n",
            "                   all         15         85      0.991      0.142      0.318       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      2.54G      1.226      1.151      1.036         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.7it/s 0.1s\n",
            "                   all         15         85      0.983       0.15      0.404       0.17\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      2.55G      1.197      1.507      1.013         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.5it/s 1.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.1it/s 0.1s\n",
            "                   all         15         85      0.957      0.175      0.409      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      2.57G      1.227      1.411      1.028         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 8.8it/s 0.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 9.6it/s 0.1s\n",
            "                   all         15         85      0.971      0.174      0.407      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      2.59G      1.265      1.423      1.048         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.6it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.6it/s 0.1s\n",
            "                   all         15         85      0.976      0.156      0.404      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30       2.6G      1.218      1.389      1.049         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.7it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.1it/s 0.1s\n",
            "                   all         15         85      0.984      0.161      0.329      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      2.62G      1.357      1.485      1.095         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.2it/s 0.1s\n",
            "                   all         15         85      0.955      0.183      0.333      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      2.64G      1.196      1.298       1.05         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.0it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.2it/s 0.1s\n",
            "                   all         15         85      0.676      0.263      0.329      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      2.66G      1.185      1.296      1.042         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.0it/s 0.1s\n",
            "                   all         15         85      0.691      0.324      0.343      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      2.67G      1.136      1.249      1.015         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.1it/s 0.1s\n",
            "                   all         15         85      0.674      0.394      0.339      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      2.68G      1.102        1.2     0.9949         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.3it/s 0.1s\n",
            "                   all         15         85      0.658        0.4      0.342      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      2.71G      1.147      1.204     0.9888         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.4it/s 0.1s\n",
            "                   all         15         85      0.663      0.402      0.347      0.196\n",
            "\n",
            "30 epochs completed in 0.008 hours.\n",
            "Optimizer stripped from /content/runs_100/baseline/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs_100/baseline/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs_100/baseline/weights/best.pt...\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.2it/s 0.1s\n",
            "                   all         15         85     0.0155      0.931      0.564      0.272\n",
            "                   Car         15         82     0.0445      0.793      0.574      0.307\n",
            "            Pedestrian          2          2    0.00151          1      0.125     0.0129\n",
            "               Cyclist          1          1   0.000584          1      0.995      0.497\n",
            "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_100/baseline\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/training/generate_img2img.py \\\n",
        "  --input_dir \"/content/drive/MyDrive/training/yolo_kitti_100/images/train\" \\\n",
        "  --output_dir \"/content/drive/MyDrive/training/synth_kitti_100\" \\\n",
        "  --only rain,snow,fog --limit 10 --strength 0.50 --steps 35 --cfg 9\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gF7L4WUIuN-",
        "outputId": "4cdd920c-a415-44d2-cc23-e97a07a64424"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-18 02:09:01.227138: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766023741.250200   97253 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766023741.257116   97253 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766023741.274684   97253 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766023741.274724   97253 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766023741.274728   97253 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766023741.274730   97253 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00, 11.30it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py:2186: FutureWarning: `enable_vae_slicing` is deprecated and will be removed in version 0.40.0. Calling `enable_vae_slicing()` on a `StableDiffusionXLImg2ImgPipeline` is deprecated and this method will be removed in a future version. Please use `pipe.vae.enable_slicing()`.\n",
            "  deprecate(\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py:2213: FutureWarning: `enable_vae_tiling` is deprecated and will be removed in version 0.40.0. Calling `enable_vae_tiling()` on a `StableDiffusionXLImg2ImgPipeline` is deprecated and this method will be removed in a future version. Please use `pipe.vae.enable_tiling()`.\n",
            "  deprecate(\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py:896: FutureWarning: `upcast_vae` is deprecated and will be removed in version 1.0.0. `upcast_vae` is deprecated. Please use `pipe.vae.to(torch.float32)`. For more details, please refer to: https://github.com/huggingface/diffusers/pull/12619#issue-3606633695.\n",
            "  deprecate(\n",
            "100% 17/17 [00:03<00:00,  5.31it/s]\n",
            "100% 17/17 [00:03<00:00,  5.50it/s]\n",
            "100% 17/17 [00:03<00:00,  5.58it/s]\n",
            "100% 17/17 [00:03<00:00,  5.52it/s]\n",
            "100% 17/17 [00:02<00:00,  5.68it/s]\n",
            "[rain] 5/10 images processed\n",
            "100% 17/17 [00:02<00:00,  5.69it/s]\n",
            "100% 17/17 [00:02<00:00,  5.69it/s]\n",
            "100% 17/17 [00:03<00:00,  5.62it/s]\n",
            "100% 17/17 [00:02<00:00,  5.71it/s]\n",
            "100% 17/17 [00:02<00:00,  5.75it/s]\n",
            "[rain] 10/10 images processed\n",
            "100% 17/17 [00:03<00:00,  5.57it/s]\n",
            "100% 17/17 [00:03<00:00,  5.64it/s]\n",
            "100% 17/17 [00:03<00:00,  5.64it/s]\n",
            "100% 17/17 [00:03<00:00,  5.64it/s]\n",
            "100% 17/17 [00:03<00:00,  5.62it/s]\n",
            "[snow] 5/10 images processed\n",
            "100% 17/17 [00:03<00:00,  5.60it/s]\n",
            "100% 17/17 [00:02<00:00,  5.68it/s]\n",
            "100% 17/17 [00:02<00:00,  5.68it/s]\n",
            "100% 17/17 [00:03<00:00,  5.66it/s]\n",
            "100% 17/17 [00:02<00:00,  5.68it/s]\n",
            "[snow] 10/10 images processed\n",
            "100% 17/17 [00:03<00:00,  5.63it/s]\n",
            "100% 17/17 [00:03<00:00,  5.64it/s]\n",
            "100% 17/17 [00:03<00:00,  5.64it/s]\n",
            "100% 17/17 [00:02<00:00,  5.69it/s]\n",
            "100% 17/17 [00:03<00:00,  5.61it/s]\n",
            "[fog] 5/10 images processed\n",
            "100% 17/17 [00:03<00:00,  5.66it/s]\n",
            "100% 17/17 [00:02<00:00,  5.71it/s]\n",
            "100% 17/17 [00:02<00:00,  5.68it/s]\n",
            "100% 17/17 [00:03<00:00,  5.64it/s]\n",
            "100% 17/17 [00:03<00:00,  5.65it/s]\n",
            "[fog] 10/10 images processed\n",
            "Finished! Images saved to: /content/drive/MyDrive/training/synth_kitti_100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/drive/MyDrive/training/generate_img2img.py\n",
        "import argparse\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "from diffusers import StableDiffusionXLImg2ImgPipeline\n",
        "\n",
        "# Strong / stormy prompts (photorealistic, severe conditions)\n",
        "PROMPTS = {\n",
        "    \"rain\": {\n",
        "        \"prompt\": (\n",
        "            \"photorealistic dashcam RAW photo, real-world severe weather, \"\n",
        "            \"violent rainstorm, torrential rain, extreme downpour, intense rain streaks, \"\n",
        "            \"large raindrops and smear on windshield, heavy water splashes, strong tire spray, \"\n",
        "            \"standing water and puddles on road, wet asphalt mirror reflections, \"\n",
        "            \"dark storm clouds, gloomy overcast sky, very low visibility, atmospheric haze, \"\n",
        "            \"motion blur in rain only, cinematic realism, natural colors, \"\n",
        "            \"same scene, preserve the exact vehicles and road layout, no object relocation\"\n",
        "        ),\n",
        "        \"negative\": (\n",
        "            \"cartoon, anime, illustration, CGI, render, text, watermark, logo, \"\n",
        "            \"extra cars, duplicated vehicles, missing vehicles, changed vehicle shape, \"\n",
        "            \"warped road, bent lanes, deformed objects, melted surfaces, geometry change, \"\n",
        "            \"sunny, clear sky, dry road, fantasy, surreal\"\n",
        "        ),\n",
        "    },\n",
        "    \"snow\": {\n",
        "        \"prompt\": (\n",
        "            \"photorealistic dashcam RAW photo, real-world severe winter storm, \"\n",
        "            \"heavy snowstorm, thick snowfall, dense snowflakes close to camera, \"\n",
        "            \"blowing snow, strong wind gusts, swirling snow, icy slush on asphalt, \"\n",
        "            \"snow buildup on road edges, frozen mist, cold gray atmosphere, \"\n",
        "            \"very low visibility, reduced contrast, realistic winter lighting, \"\n",
        "            \"cinematic realism, natural colors, \"\n",
        "            \"same scene, preserve the exact vehicles and road layout, no object relocation\"\n",
        "        ),\n",
        "        \"negative\": (\n",
        "            \"whiteout blank image, pure white frame, cartoon, anime, illustration, CGI, render, \"\n",
        "            \"text, watermark, logo, summer, green grass, tropical, sunny, \"\n",
        "            \"extra cars, duplicated vehicles, missing vehicles, changed vehicle shape, \"\n",
        "            \"warped road, deformed objects, geometry change\"\n",
        "        ),\n",
        "    },\n",
        "    \"fog\": {\n",
        "        \"prompt\": (\n",
        "            \"photorealistic dashcam RAW photo, real-world extreme dense fog, \"\n",
        "            \"very thick gray haze, heavy mist, smoke-like fog in the air (NOT fire smoke), \"\n",
        "            \"uniform volumetric fog layer, strong atmospheric perspective, \"\n",
        "            \"major contrast reduction, desaturated colors, soft edges, \"\n",
        "            \"distant objects almost disappear, very low visibility, realistic optics, \"\n",
        "            \"cinematic realism, natural colors, \"\n",
        "            \"same scene, preserve the exact vehicles and road layout, no object relocation\"\n",
        "        ),\n",
        "        \"negative\": (\n",
        "            \"fire, flames, burning, black smoke, explosion, chimney smoke, \"\n",
        "            \"cartoon, anime, illustration, CGI, render, text, watermark, logo, \"\n",
        "            \"extra cars, duplicated vehicles, missing vehicles, changed vehicle shape, \"\n",
        "            \"warped road, deformed objects, geometry change, night, pitch black\"\n",
        "        ),\n",
        "    },\n",
        "}\n",
        "\n",
        "IMG_EXTS = {\".png\", \".jpg\", \".jpeg\", \".webp\"}\n",
        "\n",
        "\n",
        "def list_images(in_dir: Path):\n",
        "    return sorted([p for p in in_dir.iterdir() if p.suffix.lower() in IMG_EXTS])\n",
        "\n",
        "\n",
        "def pad_to_multiple_of_8(img: Image.Image):\n",
        "    w, h = img.size\n",
        "    new_w = ((w + 7) // 8) * 8\n",
        "    new_h = ((h + 7) // 8) * 8\n",
        "    if new_w == w and new_h == h:\n",
        "        return img, (0, 0, w, h)\n",
        "    padded = Image.new(\"RGB\", (new_w, new_h))\n",
        "    padded.paste(img, (0, 0))\n",
        "    return padded, (0, 0, w, h)\n",
        "\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--input_dir\", required=True)\n",
        "    ap.add_argument(\"--output_dir\", required=True)\n",
        "\n",
        "    # Realistic SDXL model (you can swap if you want)\n",
        "    ap.add_argument(\"--model_id\", default=\"SG161222/RealVisXL_V4.0\")\n",
        "\n",
        "    # Defaults for \"stormy\" look (stronger than before)\n",
        "    ap.add_argument(\"--strength\", type=float, default=0.45)\n",
        "    ap.add_argument(\"--steps\", type=int, default=28)\n",
        "    ap.add_argument(\"--cfg\", type=float, default=6.5)\n",
        "    ap.add_argument(\"--seed\", type=int, default=123)\n",
        "\n",
        "    ap.add_argument(\"--limit\", type=int, default=0)\n",
        "    ap.add_argument(\"--shuffle\", action=\"store_true\")\n",
        "    ap.add_argument(\"--split\", default=\"train\")\n",
        "    ap.add_argument(\"--only\", default=\"\", help=\"comma-separated: rain,snow,fog\")\n",
        "\n",
        "    ap.add_argument(\"--cpu_offload\", action=\"store_true\")\n",
        "    ap.add_argument(\"--force_fp32\", action=\"store_true\")\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    in_dir = Path(args.input_dir)\n",
        "    out_root = Path(args.output_dir)\n",
        "\n",
        "    images = list_images(in_dir)\n",
        "    if not images:\n",
        "        raise RuntimeError(f\"No images found in: {in_dir}\")\n",
        "\n",
        "    if args.shuffle:\n",
        "        random.seed(args.seed)\n",
        "        random.shuffle(images)\n",
        "\n",
        "    if args.limit and args.limit > 0:\n",
        "        images = images[:args.limit]\n",
        "\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    if args.force_fp32 or device != \"cuda\":\n",
        "        dtype = torch.float32\n",
        "        variant = None\n",
        "    else:\n",
        "        dtype = torch.float16\n",
        "        variant = \"fp16\"\n",
        "\n",
        "    pipe = StableDiffusionXLImg2ImgPipeline.from_pretrained(\n",
        "        args.model_id,\n",
        "        torch_dtype=dtype,\n",
        "        use_safetensors=True,\n",
        "        variant=variant,\n",
        "    ).to(device)\n",
        "\n",
        "    if device == \"cuda\":\n",
        "        pipe.enable_attention_slicing()\n",
        "        pipe.enable_vae_slicing()\n",
        "        pipe.enable_vae_tiling()\n",
        "\n",
        "        # prevent black images (SDXL)\n",
        "        if hasattr(pipe, \"upcast_vae\"):\n",
        "            pipe.upcast_vae()\n",
        "        else:\n",
        "            pipe.vae.to(dtype=torch.float32)\n",
        "\n",
        "        if args.cpu_offload:\n",
        "            try:\n",
        "                import accelerate  # noqa: F401\n",
        "                pipe.enable_model_cpu_offload()\n",
        "            except Exception:\n",
        "                print(\"cpu_offload requested but 'accelerate' not available. Install: pip install accelerate\")\n",
        "\n",
        "    selected = PROMPTS\n",
        "    if args.only.strip():\n",
        "        allowed = {x.strip() for x in args.only.split(\",\") if x.strip()}\n",
        "        selected = {k: v for k, v in PROMPTS.items() if k in allowed}\n",
        "        if not selected:\n",
        "            raise RuntimeError(f\"--only had no valid keys. Use one of: {list(PROMPTS.keys())}\")\n",
        "\n",
        "    for subtype, pp in selected.items():\n",
        "        out_dir = out_root / subtype / \"images\" / args.split\n",
        "        out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        for i, img_path in enumerate(images):\n",
        "            init_img = Image.open(img_path).convert(\"RGB\")\n",
        "            padded, crop_box = pad_to_multiple_of_8(init_img)\n",
        "\n",
        "            gen = torch.Generator(device=device).manual_seed(args.seed + i)\n",
        "\n",
        "            with torch.inference_mode():\n",
        "                out = pipe(\n",
        "                    prompt=pp[\"prompt\"],\n",
        "                    negative_prompt=pp[\"negative\"],\n",
        "                    image=padded,\n",
        "                    strength=args.strength,\n",
        "                    guidance_scale=args.cfg,\n",
        "                    num_inference_steps=args.steps,\n",
        "                    generator=gen,\n",
        "                ).images[0]\n",
        "\n",
        "            out.crop(crop_box).save(out_dir / img_path.name)\n",
        "\n",
        "            if (i + 1) % 10 == 0:\n",
        "                print(f\"[{subtype}] {i+1}/{len(images)}\")\n",
        "\n",
        "    print(f\"Finished! Images saved to: {out_root}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3gs95J1JjjN",
        "outputId": "5e9191b4-0735-4401-df7a-350a73f29135"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/drive/MyDrive/training/generate_img2img.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/training/generate_img2img.py \\\n",
        "  --input_dir \"/content/drive/MyDrive/training/yolo_kitti_100/images/train\" \\\n",
        "  --output_dir \"/content/drive/MyDrive/training/synth_kitti_100\" \\\n",
        "  --only rain,snow,fog --strength 0.45 --steps 35 --cfg 7.5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YSZpiPsPezq",
        "outputId": "261d08bf-1c39-4466-9087-e57ed00d045b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-18 02:26:42.202396: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1766024802.225360  101819 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1766024802.232018  101819 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1766024802.249249  101819 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766024802.249296  101819 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766024802.249299  101819 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1766024802.249302  101819 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Flax classes are deprecated and will be removed in Diffusers v1.0.0. We recommend migrating to PyTorch classes or pinning your version of Diffusers.\n",
            "Loading pipeline components...:  29% 2/7 [00:00<00:00, 14.02it/s]`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "Loading pipeline components...: 100% 7/7 [00:00<00:00, 11.25it/s]\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py:2186: FutureWarning: `enable_vae_slicing` is deprecated and will be removed in version 0.40.0. Calling `enable_vae_slicing()` on a `StableDiffusionXLImg2ImgPipeline` is deprecated and this method will be removed in a future version. Please use `pipe.vae.enable_slicing()`.\n",
            "  deprecate(\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/pipeline_utils.py:2213: FutureWarning: `enable_vae_tiling` is deprecated and will be removed in version 0.40.0. Calling `enable_vae_tiling()` on a `StableDiffusionXLImg2ImgPipeline` is deprecated and this method will be removed in a future version. Please use `pipe.vae.enable_tiling()`.\n",
            "  deprecate(\n",
            "/usr/local/lib/python3.12/dist-packages/diffusers/pipelines/stable_diffusion_xl/pipeline_stable_diffusion_xl_img2img.py:896: FutureWarning: `upcast_vae` is deprecated and will be removed in version 1.0.0. `upcast_vae` is deprecated. Please use `pipe.vae.to(torch.float32)`. For more details, please refer to: https://github.com/huggingface/diffusers/pull/12619#issue-3606633695.\n",
            "  deprecate(\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (100 > 77). Running this sequence through the model will result in indexing errors\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (100 > 77). Running this sequence through the model will result in indexing errors\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.36it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.54it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.69it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.69it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.66it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.48it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.66it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.66it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.62it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.67it/s]\n",
            "[rain] 10/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.65it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.64it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.62it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.59it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.75it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "[rain] 20/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.85it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.62it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.75it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.65it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.63it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.69it/s]\n",
            "[rain] 30/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.80it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.75it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.86it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.69it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.22it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.80it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.80it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "[rain] 40/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.66it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.70it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.70it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "[rain] 50/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.68it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.68it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.80it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.70it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.65it/s]\n",
            "[rain] 60/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.80it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.67it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.69it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: ['rain only, cinematic realism, natural colors, same scene, preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "[rain] 70/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.63it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.70it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.83it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.86it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "[snow] 10/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.79it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.75it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.68it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "[snow] 20/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.64it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.68it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.67it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.84it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.80it/s]\n",
            "[snow] 30/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.68it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.69it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.64it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.70it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.80it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.79it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "[snow] 40/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.62it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.79it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.59it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.83it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.82it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.83it/s]\n",
            "[snow] 50/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.86it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.86it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.84it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.84it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.82it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "[snow] 60/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.75it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.70it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.65it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "[snow] 70/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.59it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.68it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.70it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.68it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.67it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.65it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.61it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.58it/s]\n",
            "[fog] 10/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.63it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.62it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.55it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.60it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.60it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.65it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.69it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.67it/s]\n",
            "[fog] 20/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.68it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.66it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.66it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.75it/s]\n",
            "[fog] 30/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.59it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.70it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.70it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.81it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.72it/s]\n",
            "[fog] 40/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.61it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.81it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.69it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.69it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.78it/s]\n",
            "[fog] 50/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.83it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.81it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.82it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.81it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "[fog] 60/70\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.79it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.71it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.75it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.84it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.77it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.74it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.73it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.75it/s]\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "The following part of your input was truncated because CLIP can only handle sequences up to 77 tokens: [', preserve the exact vehicles and road layout, no object relocation']\n",
            "100% 15/15 [00:02<00:00,  5.76it/s]\n",
            "[fog] 70/70\n",
            "Finished! Images saved to: /content/drive/MyDrive/training/synth_kitti_100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "REAL = Path(\"/content/drive/MyDrive/training/yolo_kitti_100\")\n",
        "SYN  = Path(\"/content/drive/MyDrive/training/synth_kitti_100\")\n",
        "\n",
        "subtypes = [\"rain\",\"snow\",\"fog\"]\n",
        "split = \"train\"\n",
        "\n",
        "src_lbl = REAL/\"labels\"/split\n",
        "\n",
        "for st in subtypes:\n",
        "    img_dir = SYN/st/\"images\"/split\n",
        "    out_lbl = SYN/st/\"labels\"/split\n",
        "    out_lbl.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    count = 0\n",
        "    for img in img_dir.glob(\"*\"):\n",
        "        if img.suffix.lower() not in [\".png\",\".jpg\",\".jpeg\",\".webp\"]:\n",
        "            continue\n",
        "        src = src_lbl/(img.stem+\".txt\")\n",
        "        dst = out_lbl/(img.stem+\".txt\")\n",
        "        if src.exists():\n",
        "            shutil.copy2(src, dst)\n",
        "        else:\n",
        "            dst.write_text(\"\")\n",
        "        count += 1\n",
        "\n",
        "    print(st, \"labels copied:\", count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-WTfXflPotp",
        "outputId": "f4f1a047-e6bc-48df-8c94-5bb2cb89a703"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rain labels copied: 70\n",
            "snow labels copied: 70\n",
            "fog labels copied: 70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import shutil, yaml\n",
        "\n",
        "REAL = Path(\"/content/drive/MyDrive/training/yolo_kitti_100\")\n",
        "SYN  = Path(\"/content/drive/MyDrive/training/synth_kitti_100\")\n",
        "OUT  = Path(\"/content/drive/MyDrive/training/yolo_kitti_100_aug\")\n",
        "\n",
        "if OUT.exists():\n",
        "    shutil.rmtree(OUT)\n",
        "\n",
        "# copy real train/val/test\n",
        "for split in [\"train\",\"val\",\"test\"]:\n",
        "    (OUT/\"images\"/split).mkdir(parents=True, exist_ok=True)\n",
        "    (OUT/\"labels\"/split).mkdir(parents=True, exist_ok=True)\n",
        "    shutil.copytree(REAL/\"images\"/split, OUT/\"images\"/split, dirs_exist_ok=True)\n",
        "    shutil.copytree(REAL/\"labels\"/split, OUT/\"labels\"/split, dirs_exist_ok=True)\n",
        "\n",
        "# add synth to TRAIN only (keep val/test real)\n",
        "subtypes = [\"rain\",\"snow\",\"fog\"]\n",
        "for st in subtypes:\n",
        "    img_dir = SYN/st/\"images\"/\"train\"\n",
        "    lbl_dir = SYN/st/\"labels\"/\"train\"\n",
        "\n",
        "    for img in img_dir.glob(\"*\"):\n",
        "        if img.suffix.lower() not in [\".png\",\".jpg\",\".jpeg\",\".webp\"]:\n",
        "            continue\n",
        "        new_name = f\"{img.stem}_{st}{img.suffix.lower()}\"\n",
        "        shutil.copy2(img, OUT/\"images\"/\"train\"/new_name)\n",
        "\n",
        "        src_lbl = lbl_dir/(img.stem+\".txt\")\n",
        "        dst_lbl = OUT/\"labels\"/\"train\"/f\"{img.stem}_{st}.txt\"\n",
        "        if src_lbl.exists():\n",
        "            shutil.copy2(src_lbl, dst_lbl)\n",
        "        else:\n",
        "            dst_lbl.write_text(\"\")\n",
        "\n",
        "print(\"DONE:\", OUT)\n",
        "\n",
        "# write data.yaml\n",
        "base_yaml = yaml.safe_load((REAL/\"data.yaml\").read_text())\n",
        "data = {\n",
        "    \"path\": str(OUT),\n",
        "    \"train\": \"images/train\",\n",
        "    \"val\": \"images/val\",\n",
        "    \"test\": \"images/test\",\n",
        "    \"names\": base_yaml[\"names\"],\n",
        "}\n",
        "(OUT/\"data.yaml\").write_text(yaml.safe_dump(data, sort_keys=False))\n",
        "print(\"Wrote:\", OUT/\"data.yaml\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y4GRWybU1wm",
        "outputId": "591f7912-eaad-4242-a5ce-89b0d6209fbb"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE: /content/drive/MyDrive/training/yolo_kitti_100_aug\n",
            "Wrote: /content/drive/MyDrive/training/yolo_kitti_100_aug/data.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo detect train model=yolov8n.pt \\\n",
        "  data=\"/content/drive/MyDrive/training/yolo_kitti_100_aug/data.yaml\" \\\n",
        "  epochs=30 imgsz=640 project=\"/content/runs_compare_100\" name=\"augmented\" exist_ok=True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcpddsLeU9gk",
        "outputId": "3d2f861e-6245-48da-d17d-ca4fb7a2ed31"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/training/yolo_kitti_100_aug/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=augmented, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/runs_compare_100, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs_compare_100/augmented, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.4Â±0.1 ms, read: 275.9Â±138.8 MB/s, size: 772.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100_aug/labels/train... 280 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 280/280 194.5it/s 1.4s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/training/yolo_kitti_100_aug/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.8Â±0.4 ms, read: 146.2Â±88.2 MB/s, size: 792.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100_aug/labels/val... 15 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 154.7it/s 0.1s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/training/yolo_kitti_100_aug/labels/val.cache\n",
            "Plotting labels to /content/runs_compare_100/augmented/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs_compare_100/augmented\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      2.22G      1.831      3.043      1.319         56        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 2.6it/s 7.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
            "                   all         15         85     0.0114      0.553      0.123     0.0594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      2.23G      1.716      1.795      1.251         87        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.1it/s 0.1s\n",
            "                   all         15         85     0.0111      0.533      0.124     0.0708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      2.26G      1.646       1.65      1.248         95        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.5it/s 0.1s\n",
            "                   all         15         85          1      0.023      0.113     0.0623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      2.28G      1.621      1.564      1.212         82        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.7it/s 1.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.7it/s 0.1s\n",
            "                   all         15         85      0.887     0.0447      0.096     0.0562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      2.29G      1.604      1.485      1.223         77        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.7it/s 0.1s\n",
            "                   all         15         85      0.949      0.061      0.297      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      2.31G      1.572      1.403      1.191         72        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.9it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.3it/s 0.1s\n",
            "                   all         15         85      0.557      0.512      0.539      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      2.33G      1.588      1.401      1.206         59        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.4it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.5it/s 0.1s\n",
            "                   all         15         85      0.721      0.313      0.258      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      2.35G      1.522      1.329      1.174         66        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.5it/s 0.1s\n",
            "                   all         15         85      0.925      0.255      0.367      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      2.36G      1.471      1.267      1.154        100        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.0it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.7it/s 0.1s\n",
            "                   all         15         85      0.713      0.307      0.283      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      2.38G      1.503      1.263      1.157        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.0it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.9it/s 0.1s\n",
            "                   all         15         85      0.219      0.175      0.193      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30       2.4G      1.479      1.257      1.158        122        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.4it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.2it/s 0.1s\n",
            "                   all         15         85      0.748      0.301      0.273      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      2.41G      1.389      1.208      1.124         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.6it/s 0.1s\n",
            "                   all         15         85      0.773      0.341      0.324      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      2.43G      1.405      1.175      1.132         77        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.2it/s 0.1s\n",
            "                   all         15         85      0.944      0.321      0.393      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      2.45G      1.367       1.12      1.106         94        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.1it/s 0.1s\n",
            "                   all         15         85      0.945      0.309      0.396        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      2.46G      1.406      1.152      1.135         71        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.2it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.0it/s 0.1s\n",
            "                   all         15         85      0.873      0.314      0.386      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      2.48G      1.354      1.112      1.107         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.9it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.4it/s 0.1s\n",
            "                   all         15         85      0.901      0.317      0.393      0.209\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30       2.5G       1.32       1.03      1.082         75        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.3it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.5it/s 0.1s\n",
            "                   all         15         85      0.807      0.324      0.413      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      2.52G      1.279       1.02      1.074         79        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.0it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.8it/s 0.1s\n",
            "                   all         15         85       0.91      0.325        0.4      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      2.53G      1.247     0.9775       1.07         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.2it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.8it/s 0.1s\n",
            "                   all         15         85      0.462      0.411       0.41      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      2.55G      1.259     0.9995      1.071         63        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.6it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.1it/s 0.1s\n",
            "                   all         15         85      0.693      0.402      0.407      0.154\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      2.57G      1.337      1.218      1.088         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 6.3it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.5it/s 0.1s\n",
            "                   all         15         85      0.914      0.207      0.253      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      2.58G       1.28      1.144      1.082         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 9.8it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.1it/s 0.1s\n",
            "                   all         15         85      0.739      0.341      0.321      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30       2.6G      1.252      1.066      1.064         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.9it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.8it/s 0.1s\n",
            "                   all         15         85      0.936      0.204       0.25      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      2.62G       1.21      1.028      1.048         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.3it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.2it/s 0.1s\n",
            "                   all         15         85      0.802      0.328      0.394      0.233\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      2.64G      1.175     0.9883      1.042         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.3it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.7it/s 0.1s\n",
            "                   all         15         85      0.922      0.297      0.397      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      2.65G      1.149     0.9721      1.015         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.7it/s 0.1s\n",
            "                   all         15         85      0.914       0.31      0.378      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      2.67G      1.171     0.9765      1.027         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.7it/s 0.1s\n",
            "                   all         15         85      0.923      0.308      0.399      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      2.69G      1.162     0.9622      1.022         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.2it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.3it/s 0.1s\n",
            "                   all         15         85      0.912      0.321      0.399      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30       2.7G      1.118     0.9292      1.005         50        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.0it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.1it/s 0.1s\n",
            "                   all         15         85      0.941      0.313        0.4      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      2.72G      1.135     0.9244      1.019         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.2it/s 0.1s\n",
            "                   all         15         85      0.951      0.308        0.4      0.203\n",
            "\n",
            "30 epochs completed in 0.019 hours.\n",
            "Optimizer stripped from /content/runs_compare_100/augmented/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/runs_compare_100/augmented/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/runs_compare_100/augmented/weights/best.pt...\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.5it/s 0.1s\n",
            "                   all         15         85      0.797      0.325      0.394      0.233\n",
            "                   Car         15         82      0.893      0.476      0.686      0.401\n",
            "            Pedestrian          2          2      0.498        0.5      0.496      0.297\n",
            "               Cyclist          1          1          1          0          0          0\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_compare_100/augmented\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REAL=\"/content/drive/MyDrive/training/yolo_kitti_100/data.yaml\"\n",
        "AUGD=\"/content/drive/MyDrive/training/yolo_kitti_100_aug/data.yaml\"\n",
        "PROJ=\"/content/drive/MyDrive/runs_kitti100_compare_v1\"\n",
        "\n",
        "!yolo detect train model=yolov8n.pt data=\"$REAL\" epochs=30 imgsz=640 \\\n",
        "  project=\"$PROJ\" name=\"baseline\" exist_ok=True\n",
        "\n",
        "!yolo detect train model=yolov8n.pt data=\"$AUGD\" epochs=30 imgsz=640 \\\n",
        "  project=\"$PROJ\" name=\"augmented\" exist_ok=True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YkoJM2vrVM-5",
        "outputId": "97c45fa2-2cf2-4286-827a-83c34902f35f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/training/yolo_kitti_100/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=baseline, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/runs_kitti100_compare_v1, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/runs_kitti100_compare_v1/baseline, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.0 ms, read: 305.5Â±35.2 MB/s, size: 826.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100/labels/train.cache... 70 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 70/70 804.4Kit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.3 ms, read: 230.5Â±97.8 MB/s, size: 792.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100/labels/val.cache... 15 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 94.2Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/runs_kitti100_compare_v1/baseline/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/runs_kitti100_compare_v1/baseline\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      2.19G       1.65      3.809      1.183         97        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 1.1it/s 4.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.2it/s 0.2s\n",
            "                   all         15         85    0.00964      0.472     0.0363     0.0236\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      2.21G      1.608      3.268      1.195         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.2it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.0it/s 0.1s\n",
            "                   all         15         85     0.0145      0.573     0.0732     0.0412\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      2.23G      1.658       2.41      1.142         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.4it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.4it/s 0.1s\n",
            "                   all         15         85     0.0126      0.573       0.11     0.0656\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      2.25G       1.45      1.713      1.079         53        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.5it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.4it/s 0.1s\n",
            "                   all         15         85     0.0123      0.573      0.116     0.0669\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      2.26G      1.459      1.588      1.106         88        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.3it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.5it/s 0.1s\n",
            "                   all         15         85     0.0114      0.549      0.127     0.0616\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      2.26G      1.445       1.59      1.095         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.6it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.8it/s 0.1s\n",
            "                   all         15         85     0.0109      0.533      0.115      0.046\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      2.26G      1.422      1.486      1.104         81        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.3it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.6it/s 0.1s\n",
            "                   all         15         85     0.0124      0.553      0.126     0.0509\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      2.26G      1.311      1.418      1.106         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.1it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.6it/s 0.1s\n",
            "                   all         15         85     0.0126      0.553      0.136     0.0645\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      2.26G      1.361      1.346      1.128         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 10.9it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.8it/s 0.1s\n",
            "                   all         15         85     0.0141      0.577      0.439      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      2.26G        1.3       1.36      1.077         50        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.4it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.8it/s 0.1s\n",
            "                   all         15         85     0.0137      0.573      0.483      0.205\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      2.26G      1.306      1.464       1.05         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.1it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.5it/s 0.1s\n",
            "                   all         15         85     0.0147      0.585      0.501      0.237\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      2.26G       1.25      1.311       1.04         61        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.2it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.1it/s 0.1s\n",
            "                   all         15         85     0.0157      0.931      0.514       0.27\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      2.26G      1.309      1.291      1.042         74        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.7it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.7it/s 0.1s\n",
            "                   all         15         85     0.0155      0.931      0.561      0.271\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      2.26G      1.315      1.272      1.055         59        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.8it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.0it/s 0.1s\n",
            "                   all         15         85      0.987     0.0988      0.387      0.178\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      2.26G      1.227      1.221      1.051         68        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.3it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.6it/s 0.1s\n",
            "                   all         15         85      0.986     0.0948      0.307       0.16\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      2.27G      1.199      1.206      1.043         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.8it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.2it/s 0.1s\n",
            "                   all         15         85      0.975     0.0976      0.301      0.142\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      2.27G      1.164      1.125      1.031         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.8it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.3it/s 0.1s\n",
            "                   all         15         85       0.98      0.125      0.311      0.153\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30      2.27G      1.203      1.108       1.03         79        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.7it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.7it/s 0.1s\n",
            "                   all         15         85      0.991       0.14      0.313      0.149\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      2.29G      1.216      1.131      1.013         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.7it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.5it/s 0.1s\n",
            "                   all         15         85      0.991      0.142      0.318       0.15\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      2.31G      1.226      1.151      1.036         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.7it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.3it/s 0.1s\n",
            "                   all         15         85      0.983       0.15      0.404       0.17\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      2.31G      1.197      1.507      1.013         30        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 3.5it/s 1.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.1it/s 0.1s\n",
            "                   all         15         85      0.957      0.175      0.409      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      2.31G      1.227      1.411      1.028         33        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 9.4it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.2it/s 0.1s\n",
            "                   all         15         85      0.971      0.174      0.407      0.187\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      2.31G      1.265      1.423      1.048         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.5it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.6it/s 0.1s\n",
            "                   all         15         85      0.976      0.156      0.404      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      2.31G      1.218      1.389      1.049         35        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.0it/s 0.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.8it/s 0.1s\n",
            "                   all         15         85      0.984      0.161      0.329      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      2.31G      1.357      1.485      1.095         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 11.8it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.8it/s 0.1s\n",
            "                   all         15         85      0.955      0.183      0.333      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      2.31G      1.196      1.298       1.05         24        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.5it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.9it/s 0.1s\n",
            "                   all         15         85      0.676      0.263      0.329      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      2.31G      1.185      1.296      1.042         34        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.5it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.6it/s 0.1s\n",
            "                   all         15         85      0.691      0.324      0.343      0.173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      2.31G      1.136      1.249      1.015         31        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.1it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 15.0it/s 0.1s\n",
            "                   all         15         85      0.674      0.394      0.339      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      2.31G      1.102        1.2     0.9949         25        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 12.7it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.2it/s 0.1s\n",
            "                   all         15         85      0.658        0.4      0.342      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      2.31G      1.147      1.204     0.9888         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 5/5 13.1it/s 0.4s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.5it/s 0.1s\n",
            "                   all         15         85      0.663      0.402      0.347      0.196\n",
            "\n",
            "30 epochs completed in 0.008 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/runs_kitti100_compare_v1/baseline/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/runs_kitti100_compare_v1/baseline/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/runs_kitti100_compare_v1/baseline/weights/best.pt...\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 16.8it/s 0.1s\n",
            "                   all         15         85     0.0155      0.931      0.564      0.272\n",
            "                   Car         15         82     0.0445      0.793      0.574      0.307\n",
            "            Pedestrian          2          2    0.00151          1      0.125     0.0129\n",
            "               Cyclist          1          1   0.000584          1      0.995      0.497\n",
            "Speed: 0.1ms preprocess, 0.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/runs_kitti100_compare_v1/baseline\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/drive/MyDrive/training/yolo_kitti_100_aug/data.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=augmented, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/runs_kitti100_compare_v1, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/runs_kitti100_compare_v1/augmented, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
            "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 299.5Â±126.1 MB/s, size: 772.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100_aug/labels/train.cache... 280 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 280/280 2.8Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.5Â±0.1 ms, read: 223.3Â±93.3 MB/s, size: 792.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100_aug/labels/val.cache... 15 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 88.2Kit/s 0.0s\n",
            "Plotting labels to /content/drive/MyDrive/runs_kitti100_compare_v1/augmented/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/runs_kitti100_compare_v1/augmented\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/30      2.21G      1.831      3.043      1.319         56        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 2.7it/s 6.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
            "                   all         15         85     0.0114      0.553      0.123     0.0594\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/30      2.23G      1.716      1.795      1.251         87        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.5it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.5it/s 0.1s\n",
            "                   all         15         85     0.0111      0.533      0.124     0.0708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/30      2.25G      1.646       1.65      1.248         95        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.4it/s 0.1s\n",
            "                   all         15         85          1      0.023      0.113     0.0623\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/30      2.27G      1.621      1.564      1.212         82        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.3it/s 0.1s\n",
            "                   all         15         85      0.887     0.0447      0.096     0.0562\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/30      2.28G      1.604      1.485      1.223         77        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.3it/s 0.1s\n",
            "                   all         15         85      0.949      0.061      0.297      0.133\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/30      2.28G      1.572      1.403      1.191         72        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.6it/s 0.1s\n",
            "                   all         15         85      0.557      0.512      0.539      0.182\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/30      2.28G      1.588      1.401      1.206         59        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.3it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.5it/s 0.1s\n",
            "                   all         15         85      0.721      0.313      0.258      0.125\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/30      2.28G      1.522      1.329      1.174         66        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.8it/s 0.1s\n",
            "                   all         15         85      0.925      0.255      0.367      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/30      2.28G      1.471      1.267      1.154        100        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.9it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.5it/s 0.1s\n",
            "                   all         15         85      0.713      0.307      0.283      0.136\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/30      2.28G      1.503      1.263      1.157        116        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.9it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.4it/s 0.1s\n",
            "                   all         15         85      0.219      0.175      0.193      0.104\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/30      2.28G      1.479      1.257      1.158        122        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.9it/s 0.1s\n",
            "                   all         15         85      0.748      0.301      0.273      0.152\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/30      2.28G      1.389      1.208      1.124         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.5it/s 0.1s\n",
            "                   all         15         85      0.773      0.341      0.324      0.159\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/30      2.28G      1.405      1.175      1.132         77        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.2it/s 0.1s\n",
            "                   all         15         85      0.944      0.321      0.393      0.207\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/30      2.28G      1.367       1.12      1.106         94        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.9it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.0it/s 0.1s\n",
            "                   all         15         85      0.945      0.309      0.396        0.2\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/30      2.29G      1.406      1.152      1.135         71        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.0it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.0it/s 0.1s\n",
            "                   all         15         85      0.873      0.314      0.386      0.184\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/30      2.29G      1.354      1.112      1.107         52        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.2it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.0it/s 0.1s\n",
            "                   all         15         85      0.901      0.317      0.393      0.209\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/30      2.29G       1.32       1.03      1.082         75        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.3it/s 0.1s\n",
            "                   all         15         85      0.807      0.324      0.413      0.222\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/30       2.3G      1.279       1.02      1.074         79        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.2it/s 1.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 14.0it/s 0.1s\n",
            "                   all         15         85       0.91      0.325        0.4      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/30      2.31G      1.247     0.9775       1.07         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.6it/s 0.1s\n",
            "                   all         15         85      0.462      0.411       0.41      0.167\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/30      2.32G      1.259     0.9995      1.071         63        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.9it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.0it/s 0.1s\n",
            "                   all         15         85      0.693      0.402      0.407      0.154\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/30      2.32G      1.337      1.218      1.088         49        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 5.8it/s 3.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.5it/s 0.1s\n",
            "                   all         15         85      0.914      0.207      0.253      0.137\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/30      2.33G       1.28      1.144      1.082         39        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 8.0it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.8it/s 0.1s\n",
            "                   all         15         85      0.739      0.341      0.321      0.172\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/30      2.33G      1.252      1.066      1.064         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.7it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.5it/s 0.1s\n",
            "                   all         15         85      0.936      0.204       0.25      0.139\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/30      2.33G       1.21      1.028      1.048         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 10.8it/s 1.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.5it/s 0.1s\n",
            "                   all         15         85      0.802      0.328      0.394      0.233\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/30      2.33G      1.175     0.9883      1.042         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.2it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.1it/s 0.1s\n",
            "                   all         15         85      0.922      0.297      0.397      0.197\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/30      2.33G      1.149     0.9721      1.015         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.0it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.8it/s 0.1s\n",
            "                   all         15         85      0.914       0.31      0.378      0.177\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/30      2.33G      1.171     0.9765      1.027         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 11.5it/s 0.1s\n",
            "                   all         15         85      0.923      0.308      0.399      0.188\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/30      2.33G      1.162     0.9622      1.022         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.3it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.7it/s 0.1s\n",
            "                   all         15         85      0.912      0.321      0.399      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/30      2.33G      1.118     0.9292      1.005         50        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 10.6it/s 0.1s\n",
            "                   all         15         85      0.941      0.313        0.4      0.186\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/30      2.33G      1.135     0.9244      1.019         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 18/18 11.1it/s 1.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 12.3it/s 0.1s\n",
            "                   all         15         85      0.951      0.308        0.4      0.203\n",
            "\n",
            "30 epochs completed in 0.019 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/runs_kitti100_compare_v1/augmented/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/drive/MyDrive/runs_kitti100_compare_v1/augmented/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/drive/MyDrive/runs_kitti100_compare_v1/augmented/weights/best.pt...\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 13.9it/s 0.1s\n",
            "                   all         15         85      0.797      0.325      0.394      0.233\n",
            "                   Car         15         82      0.893      0.476      0.686      0.401\n",
            "            Pedestrian          2          2      0.498        0.5      0.496      0.297\n",
            "               Cyclist          1          1          1          0          0          0\n",
            "Speed: 0.1ms preprocess, 0.7ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/runs_kitti100_compare_v1/augmented\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install ultralytics\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkpYNug5Vjns",
        "outputId": "2f060629-067b-4217-b4ad-7e3c10f7b4ed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4QRsjykYVLF",
        "outputId": "acefb9b8-c23b-4f31-b874-a31a992a1a51"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%env BASELINE_MODEL=/content/drive/MyDrive/runs_kitti100_compare_v1/baseline/weights/best.pt\n",
        "%env AUG_MODEL=/content/drive/MyDrive/runs_kitti100_compare_v1/augmented/weights/best.pt\n",
        "%env REAL=/content/drive/MyDrive/training/yolo_kitti_100/data.yaml\n",
        "\n",
        "!yolo detect val model=\"$BASELINE_MODEL\" data=\"$REAL\" split=test project=\"/content/runs_val\" name=val_baseline\n",
        "!yolo detect val model=\"$AUG_MODEL\"      data=\"$REAL\" split=test project=\"/content/runs_val\" name=val_augmented\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cLvkcwa1kOa",
        "outputId": "e68afaf3-713c-4827-9695-a22be21166ee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: BASELINE_MODEL=/content/drive/MyDrive/runs_kitti100_compare_v1/baseline/weights/best.pt\n",
            "env: AUG_MODEL=/content/drive/MyDrive/runs_kitti100_compare_v1/augmented/weights/best.pt\n",
            "env: REAL=/content/drive/MyDrive/training/yolo_kitti_100/data.yaml\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 324.5Â±33.0 MB/s, size: 852.5 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100/labels/test.cache... 15 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 222.3Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
            "                   all         15         73      0.013      0.749      0.346      0.207\n",
            "                   Car         12         56      0.031      0.804      0.582      0.366\n",
            "            Pedestrian          5         13    0.00597      0.692      0.211      0.121\n",
            "               Cyclist          2          4    0.00195       0.75      0.246      0.136\n",
            "Speed: 0.3ms preprocess, 4.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_val/val_baseline2\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n",
            "Ultralytics 8.3.240 ğŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-80GB, 81222MiB)\n",
            "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.3Â±0.1 ms, read: 296.1Â±31.0 MB/s, size: 818.7 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/training/yolo_kitti_100/labels/test.cache... 15 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 15/15 242.0Kit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
            "                   all         15         73      0.389      0.425      0.387      0.234\n",
            "                   Car         12         56      0.582      0.796      0.742      0.466\n",
            "            Pedestrian          5         13      0.241      0.308      0.282      0.164\n",
            "               Cyclist          2          4      0.343      0.171      0.137     0.0706\n",
            "Speed: 0.2ms preprocess, 5.6ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs_val/val_augmented\u001b[0m\n",
            "ğŸ’¡ Learn more at https://docs.ultralytics.com/modes/val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "base = pd.read_csv(\"/content/drive/MyDrive/runs_kitti100_compare_v1/baseline/results.csv\").tail(1).assign(model=\"baseline\")\n",
        "aug  = pd.read_csv(\"/content/drive/MyDrive/runs_kitti100_compare_v1/augmented/results.csv\").tail(1).assign(model=\"augmented\")\n",
        "\n",
        "df = pd.concat([base, aug], ignore_index=True)\n",
        "\n",
        "(df.style.hide(axis=\"index\").format(precision=4))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "p1NV8Dao1wac",
        "outputId": "721a4bfa-7626-4873-d6fc-35ca154a0fa7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7bfffaef9250>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "</style>\n",
              "<table id=\"T_7a6d6\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th id=\"T_7a6d6_level0_col0\" class=\"col_heading level0 col0\" >epoch</th>\n",
              "      <th id=\"T_7a6d6_level0_col1\" class=\"col_heading level0 col1\" >time</th>\n",
              "      <th id=\"T_7a6d6_level0_col2\" class=\"col_heading level0 col2\" >train/box_loss</th>\n",
              "      <th id=\"T_7a6d6_level0_col3\" class=\"col_heading level0 col3\" >train/cls_loss</th>\n",
              "      <th id=\"T_7a6d6_level0_col4\" class=\"col_heading level0 col4\" >train/dfl_loss</th>\n",
              "      <th id=\"T_7a6d6_level0_col5\" class=\"col_heading level0 col5\" >metrics/precision(B)</th>\n",
              "      <th id=\"T_7a6d6_level0_col6\" class=\"col_heading level0 col6\" >metrics/recall(B)</th>\n",
              "      <th id=\"T_7a6d6_level0_col7\" class=\"col_heading level0 col7\" >metrics/mAP50(B)</th>\n",
              "      <th id=\"T_7a6d6_level0_col8\" class=\"col_heading level0 col8\" >metrics/mAP50-95(B)</th>\n",
              "      <th id=\"T_7a6d6_level0_col9\" class=\"col_heading level0 col9\" >val/box_loss</th>\n",
              "      <th id=\"T_7a6d6_level0_col10\" class=\"col_heading level0 col10\" >val/cls_loss</th>\n",
              "      <th id=\"T_7a6d6_level0_col11\" class=\"col_heading level0 col11\" >val/dfl_loss</th>\n",
              "      <th id=\"T_7a6d6_level0_col12\" class=\"col_heading level0 col12\" >lr/pg0</th>\n",
              "      <th id=\"T_7a6d6_level0_col13\" class=\"col_heading level0 col13\" >lr/pg1</th>\n",
              "      <th id=\"T_7a6d6_level0_col14\" class=\"col_heading level0 col14\" >lr/pg2</th>\n",
              "      <th id=\"T_7a6d6_level0_col15\" class=\"col_heading level0 col15\" >model</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td id=\"T_7a6d6_row0_col0\" class=\"data row0 col0\" >30</td>\n",
              "      <td id=\"T_7a6d6_row0_col1\" class=\"data row0 col1\" >30.1210</td>\n",
              "      <td id=\"T_7a6d6_row0_col2\" class=\"data row0 col2\" >1.1473</td>\n",
              "      <td id=\"T_7a6d6_row0_col3\" class=\"data row0 col3\" >1.2040</td>\n",
              "      <td id=\"T_7a6d6_row0_col4\" class=\"data row0 col4\" >0.9888</td>\n",
              "      <td id=\"T_7a6d6_row0_col5\" class=\"data row0 col5\" >0.6632</td>\n",
              "      <td id=\"T_7a6d6_row0_col6\" class=\"data row0 col6\" >0.4024</td>\n",
              "      <td id=\"T_7a6d6_row0_col7\" class=\"data row0 col7\" >0.3469</td>\n",
              "      <td id=\"T_7a6d6_row0_col8\" class=\"data row0 col8\" >0.1964</td>\n",
              "      <td id=\"T_7a6d6_row0_col9\" class=\"data row0 col9\" >1.4607</td>\n",
              "      <td id=\"T_7a6d6_row0_col10\" class=\"data row0 col10\" >1.1249</td>\n",
              "      <td id=\"T_7a6d6_row0_col11\" class=\"data row0 col11\" >1.1832</td>\n",
              "      <td id=\"T_7a6d6_row0_col12\" class=\"data row0 col12\" >0.0001</td>\n",
              "      <td id=\"T_7a6d6_row0_col13\" class=\"data row0 col13\" >0.0001</td>\n",
              "      <td id=\"T_7a6d6_row0_col14\" class=\"data row0 col14\" >0.0001</td>\n",
              "      <td id=\"T_7a6d6_row0_col15\" class=\"data row0 col15\" >baseline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td id=\"T_7a6d6_row1_col0\" class=\"data row1 col0\" >30</td>\n",
              "      <td id=\"T_7a6d6_row1_col1\" class=\"data row1 col1\" >69.3426</td>\n",
              "      <td id=\"T_7a6d6_row1_col2\" class=\"data row1 col2\" >1.1355</td>\n",
              "      <td id=\"T_7a6d6_row1_col3\" class=\"data row1 col3\" >0.9244</td>\n",
              "      <td id=\"T_7a6d6_row1_col4\" class=\"data row1 col4\" >1.0190</td>\n",
              "      <td id=\"T_7a6d6_row1_col5\" class=\"data row1 col5\" >0.9509</td>\n",
              "      <td id=\"T_7a6d6_row1_col6\" class=\"data row1 col6\" >0.3078</td>\n",
              "      <td id=\"T_7a6d6_row1_col7\" class=\"data row1 col7\" >0.3999</td>\n",
              "      <td id=\"T_7a6d6_row1_col8\" class=\"data row1 col8\" >0.2026</td>\n",
              "      <td id=\"T_7a6d6_row1_col9\" class=\"data row1 col9\" >1.4055</td>\n",
              "      <td id=\"T_7a6d6_row1_col10\" class=\"data row1 col10\" >0.9477</td>\n",
              "      <td id=\"T_7a6d6_row1_col11\" class=\"data row1 col11\" >1.1830</td>\n",
              "      <td id=\"T_7a6d6_row1_col12\" class=\"data row1 col12\" >0.0001</td>\n",
              "      <td id=\"T_7a6d6_row1_col13\" class=\"data row1 col13\" >0.0001</td>\n",
              "      <td id=\"T_7a6d6_row1_col14\" class=\"data row1 col14\" >0.0001</td>\n",
              "      <td id=\"T_7a6d6_row1_col15\" class=\"data row1 col15\" >augmented</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "57NwDLJz2Qmo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}